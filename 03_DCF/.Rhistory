path
getwd
getwd()
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
get_wd()
getwd()
getwd() == abs_path
abs_path
getwd("..")
?getwd
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
if( getwd() != abs_path){
setwd(abs_path)
}
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
if( getwd() != abs_path){
setwd(abs_path)
}
searches <- read.csv( "/csv_data/LLM_searches.csv" )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( data_path, "LLM_searches.csv" ) )
paste0( data_path, "LLM_searches.csv" )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( data_path, "LLM_searches.csv" ) )
getwd()
paste0( data_path, "LLM_searches.csv" )
read.csv( paste0( data_path, "LLM_searches.csv" ) )
read.csv( ""../csv_data/LLM_searches.csv"" )
read.csv( ../csv_data/LLM_searches.csv" )
""
read.csv("../csv_data/LLM_searches.csv")
read.csv("../csv_data/NVDA.csv")
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( data_path, "LLM_searches.csv" ) )
find_peaks <- function(
ticker,                   # str: Ticker representing a company/entity
do_print_summary = FALSE, # bool: should the model summary be printed?
peaks_df = data.frame()   # dataframe: df of dates when stock prices peaked per company
){
has_peaks_df <- nrow( peaks_df ) > 0
tick <- read.csv( paste0( "../csv_data/", ticker, "_stock_history.csv" ) )
tick$Date <- as.Date( tick$Date, format = "%Y-%m-%d" )
tick$gpt_release <- 1 * ( tick$Date > "2022-11-30" )
if( has_peaks_df ){
tick$second_peak <- 1 * ( tick$Date > peaks_df$Date[ peaks_df$Ticker == ticker ] )
}
tick <- tick[ ( tick$Date >= "2010-01-01" ), ]
recent_change_ind <- which.max( tick$Adj.Close )
recent_change <- tick$Date[ recent_change_ind ]
shift_back <- 400
if( recent_change_ind - shift_back < 0){
shift_back <- 0
}
prior_change_ind <- which.max( tick$Adj.Close[ 1:( recent_change_ind - shift_back ) ] )
if( has_peaks_df ){
model <- lm( log( Adj.Close ) ~ Date * second_peak * gpt_release, data = tick )
} else{
model <- lm( log( Adj.Close ) ~ Date * gpt_release, data = tick )
}
plot( tick$Date, tick$Adj.Close, type="l",
main = ticker,
xlab = "Date",
ylab =  "Adjusted Closing Price" )
#points( tick$Date[ recent_change_ind ], tick$Adj.Close[ recent_change_ind ],
#        type = "p",
#        col = "red" )
points( tick$Date[ prior_change_ind ], tick$Adj.Close[ prior_change_ind ],
type = "p",
col = "red" )
lines( tick$Date, exp( model$fitted.values ), col="red" )
if( do_print_summary ){
print( ticker )
print( summary( model ) )
}
tick$Date <- as.character( tick$Date )
tick$Ticker <- ticker
result <- tick[ prior_change_ind,]
return( result )
}
prior_change_df <- data.frame(Date = character(),
Ticker = character() ,
Adj.Price = numeric())
tickers <- c("NVDA", "AMD", "TSM", "ASML", "MU", "AMAT",
"GOOG", "AAPL", "META", "TSLA", "DUK",
"GLD", "X", "PG", "TLT","CVS", "VGIT", "GOVT")
k <- 1
for( ticker in tickers ){
prior <- find_peaks( ticker )
prior_change_df[ k,] <- prior[, c( "Date", "Ticker", "Adj.Close" ) ]
k <- k + 1
}
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
getwd()
getwd("..")
file.path( getwd() )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
getwd()
list.dirs()
list.files()
list.files("..")
list.files("../csv_data")
read.csv("../csv_data/00_wacc_list.csv")
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( data_path, "03_LLM_searches.csv" ) )
read.csv("../csv_data/03_LLM_searches.csv")
searches <- read.csv( paste0( data_path, "03_LLM_searches.csv" ) )
"../csv_data/03_LLM_searches.csv"
data_path
paste0( data_path, "03_LLM_searches.csv" )
head(read.csv("../csv_data/03_LLM_searches.csv"))
head(read.csv(paste0( data_path, "03_LLM_searches.csv" ) )
)
searches <- read.csv( paste0( data_path, "03_LLM_searches.csv" ) )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
rel_data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
paste0( rel_data_path, "03_LLM_searches.csv" )
read.csv("../csv_data/03_LLM_searches.csv")
read.csv(paste0( rel_data_path, "03_LLM_searches.csv" ))
read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
getwd()
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
path_to_root <- ".."
rel_data_path <- paste0( path_to_root, "/csv_data/" )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
rel_data_path <- paste0( abs_path, "/csv_data/" )
searches <- read.csv( paste0( rel_data_path, "03_LLM_searches.csv" ) )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
data_path <- paste0( abs_path, "/csv_data/" )
searches <- read.csv( paste0( data_path, "03_LLM_searches.csv" ) )
colnames( searches ) <- c( "Week", "ChatGPT", "AI", "Artificial.Intelligence" )
searches$ChatGPT[ searches$ChatGPT == "<1" ] <- 0
searches$ChatGPT <- as.numeric( searches$ChatGPT )
searches.unpivot <- cbind( searches$Week, stack( searches[ -1 ] ) )
colnames( searches.unpivot ) <- c( "Week", "Searches", "Search.Term" )
searches.unpivot$Search.Term <- as.character( searches.unpivot$Search.Term )
searches.unpivot$Week <- as.Date( searches.unpivot$Week )
ggplot( data = searches.unpivot,
aes( x = Week, y = Searches, col = Search.Term) ) +
geom_line() +
labs( title = "Searches over Time per Search Term",
col = "Search Term" ) +
theme( legend.position = c( 0.87, 0.18 ) )
rm( list = ls() )
library( ggplot2 )
library( dplyr )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
data_path <- paste0( abs_path, "/csv_data/" )
searches <- read.csv( paste0( data_path, "03_LLM_searches.csv" ) )
colnames( searches ) <- c( "Week", "ChatGPT", "AI", "Artificial.Intelligence" )
searches$ChatGPT[ searches$ChatGPT == "<1" ] <- 0
searches$ChatGPT <- as.numeric( searches$ChatGPT )
searches.unpivot <- cbind( searches$Week, stack( searches[ -1 ] ) )
colnames( searches.unpivot ) <- c( "Week", "Searches", "Search.Term" )
searches.unpivot$Search.Term <- as.character( searches.unpivot$Search.Term )
searches.unpivot$Week <- as.Date( searches.unpivot$Week )
ggplot( data = searches.unpivot,
aes( x = Week, y = Searches, col = Search.Term) ) +
geom_line() +
labs( title = "Searches over Time per Search Term",
col = "Search Term" ) +
theme( legend.position = c( 0.87, 0.18 ) )
find_peaks <- function(
ticker,                   # str: Ticker representing a company/entity
do_print_summary = FALSE, # bool: should the model summary be printed?
peaks_df = data.frame()   # dataframe: df of dates when stock prices peaked per company
){
has_peaks_df <- nrow( peaks_df ) > 0
tick <- read.csv( paste0( data_path, ticker, "_stock_history.csv" ) )
tick$Date <- as.Date( tick$Date, format = "%Y-%m-%d" )
tick$gpt_release <- 1 * ( tick$Date > "2022-11-30" )
if( has_peaks_df ){
tick$second_peak <- 1 * ( tick$Date > peaks_df$Date[ peaks_df$Ticker == ticker ] )
}
tick <- tick[ ( tick$Date >= "2010-01-01" ), ]
recent_change_ind <- which.max( tick$Adj.Close )
recent_change <- tick$Date[ recent_change_ind ]
shift_back <- 400
if( recent_change_ind - shift_back < 0){
shift_back <- 0
}
prior_change_ind <- which.max( tick$Adj.Close[ 1:( recent_change_ind - shift_back ) ] )
if( has_peaks_df ){
model <- lm( log( Adj.Close ) ~ Date * second_peak * gpt_release, data = tick )
} else{
model <- lm( log( Adj.Close ) ~ Date * gpt_release, data = tick )
}
plot( tick$Date, tick$Adj.Close, type="l",
main = ticker,
xlab = "Date",
ylab =  "Adjusted Closing Price" )
#points( tick$Date[ recent_change_ind ], tick$Adj.Close[ recent_change_ind ],
#        type = "p",
#        col = "red" )
points( tick$Date[ prior_change_ind ], tick$Adj.Close[ prior_change_ind ],
type = "p",
col = "red" )
lines( tick$Date, exp( model$fitted.values ), col="red" )
if( do_print_summary ){
print( ticker )
print( summary( model ) )
}
tick$Date <- as.character( tick$Date )
tick$Ticker <- ticker
result <- tick[ prior_change_ind,]
return( result )
}
prior_change_df <- data.frame(Date = character(),
Ticker = character() ,
Adj.Price = numeric())
tickers <- c("NVDA", "AMD", "TSM", "ASML", "MU", "AMAT",
"GOOG", "AAPL", "META", "TSLA", "DUK",
"GLD", "X", "PG", "TLT","CVS", "VGIT", "GOVT")
k <- 1
for( ticker in tickers ){
prior <- find_peaks( ticker )
prior_change_df[ k,] <- prior[, c( "Date", "Ticker", "Adj.Close" ) ]
k <- k + 1
}
for( ticker in tickers ){
two_change_points <- find_peaks( ticker, TRUE, prior_change_df)
}
# chat gpt not significant to AAPL, maybe not DUK, PG, maybe not VGIT
tickers <- c("NVDA", "AMD", "TSM", "ASML", "MU", "AMAT",
"GOOG", "AAPL", "META", "TSLA", "DUK",
"GLD", "X", "PG", "TLT","CVS", "VGIT", "GOVT")
company <- tickers[ 7 ]
tick <- read.csv( paste0( data_path, ticker, "_stock_history.csv" ) )
tick$Date <- as.Date(tick$Date, format="%Y-%m-%d")
tick$gpt_release <- 1 * (tick$Date > "2022-11-30")
tick$second_peak <- 1 * ( tick$Date > prior_change_df$Date[ prior_change_df$Ticker == company ] )
tick <- tick[tick$Date > "2010-01-01",]
#pgram(tick$Adj.Close)
m1 <- lm(log(Adj.Close) ~ Date, data=tick)
m2 <- lm(log(Adj.Close) ~ Date + gpt_release, data=tick)
m3 <- lm(log(Adj.Close) ~ Date*gpt_release, data=tick)
m4 <- lm(log(Adj.Close) ~ Date*second_peak*gpt_release, data=tick)
summary(m4)
plot(tick$Date, tick$Adj.Close, type="l", main=company,
xlab = "Date", ylab = "Adjusted Closing Price"); lines(tick$Date, exp(m4$fitted.values), col="red")
tickers <- c("NVDA", "AMD", "TSM", "ASML", "MU", "AMAT",
"GOOG", "AAPL", "META", "TSLA", "DUK",
"GLD", "X", "PG", "TLT","CVS", "VGIT", "GOVT")
all_tickers <- data.frame(Date = character(),
Ticker = character() ,
Adj.Price = numeric()
)
for( ticker in tickers ){
tick <- read.csv( paste0( data_path, ticker, "_stock_history.csv" ) )
tick$Date <- as.Date(tick$Date, format="%Y-%m-%d")
tick$gpt_release <- 1 * (tick$Date > "2022-11-30")
}
library( quantmod )
library( finreportr )
library( dplyr )
library( randomForest )
library( ggplot2 )
abs_path <- 'C:/Users/nthnt/Nextcloud/02 Projects/School/2024 Summer UCLA Stat 417 - Stat Models in Finance/FModel/'
data_path <- paste0( abs_path, "/csv_data/" )
scale_scaler <- function(
# standardizes a vector while retaining the original + transformations used
# returns: dataframe of old vec, transformed vec, and centering/scaling factors used
x_vec # array: array of numerics
)
{
center  <- mean( x_vec )
scale   <- sd( x_vec )
scaled  <- ( x_vec - center ) / scale
results <- data.frame(
no.transform = x_vec ,
transformed  = scaled ,
center       = center ,
scale        = scale
)
return( results )
}
set.seed( 1 )
cash_flow                     <- read.csv( paste0( data_path, "01_cash_flow.csv" ) )
cash_flow$this.year           <- as.numeric( substr( cash_flow$index , 1 , 4 ) )
cash_flow$prev.year           <- cash_flow$this.year - 1
cash_flow_curr_prev           <- merge( cash_flow, cash_flow,
by.x = c( "Ticker" , "this.year" ) ,
by.y = c( "Ticker" , "prev.year" ) )
cash_flow_curr_prev           <- cash_flow_curr_prev[ c( "Ticker" ,
"this.year" ,
"this.year.y" ,
"Free.Cash.Flow.x" ,
"Free.Cash.Flow.y" ) ]
colnames(cash_flow_curr_prev) <- c("Ticker",
"prev.year",
"this.year",
"prev.CF",
"this.CF")
cash_flow_curr_prev$Ticker    <- as.factor( cash_flow_curr_prev$Ticker )
prev.CF_scaled                     <- scale_scaler( cash_flow_curr_prev$prev.CF )
cash_flow_curr_prev$prev.CF.scaled <- prev.CF_scaled$transformed
this.CF_scaled                     <- scale_scaler( cash_flow_curr_prev$this.CF )
cash_flow_curr_prev$this.CF.scaled <- this.CF_scaled$transformed
train_index <- sample( 1:nrow( cash_flow_curr_prev ) ,
nrow( cash_flow_curr_prev ) * 0.7 ,
replace = F )
train       <- cash_flow_curr_prev[ train_index , ]
test        <- cash_flow_curr_prev[ -train_index , ]
m1 <- lm( formula = this.CF.scaled ~ Ticker + this.year + prev.CF.scaled ,
data = train )
m2 <- randomForest( this.CF.scaled ~ Ticker + this.year + prev.CF.scaled ,
data = train ,
importance = TRUE ,
proximity = TRUE)
m1_pred     <- predict( m1, newdata = test )
m2_pred     <- predict( m2, newdata = test )
m1_pred_mse <- mean( ( test$this.CF.scaled - m1_pred )^2 )
m2_pred_mse <- mean( ( test$this.CF.scaled - m2_pred )^2 )
cat( "m1 pred mse = ", m1_pred_mse ,
"m2 pred mse = ", m2_pred_mse )
ticker_mask      <- cash_flow_curr_prev$Ticker == "NVDA"
ticker_max_year <- max( cash_flow_curr_prev$this.year[ ticker_mask ] )
recent_year_mask <- cash_flow_curr_prev$this.year == ticker_max_year
new_data         <- cash_flow_curr_prev[ ticker_mask & recent_year_mask , ]
print( "linear pred" )
predict( m1, newdata = new_data
) * this.CF_scaled$scale[ 1 ] + this.CF_scaled$center[ 1 ]
print( "rf pred" )
predict( m2, newdata = new_data
) * this.CF_scaled$scale[ 1 ] + this.CF_scaled$center[ 1 ]
forecast <- function(
# function to forecast cashflow into the future with a list of tickers
# returns dataframe of forecasted cashflow
tickers,         # array: list of strings, each representing a ticker
num_years_ahead, # int: number of years to forecast
history,         # data.frame: dataframe of historical cash flow
model            # lm object: model used to forecast, should be trained using history
){
predictions <- data.frame(Ticker         = character() ,
prev.year      = integer() ,
this.year      = integer() ,
prev.CF        = numeric() ,
this.CF        = numeric() ,
prev.CF.scaled = numeric() ,
this.CF.scaled = numeric() )
h <- num_years_ahead
k <- 1
for( ticker in tickers ){
if( k %% h == 1 ){
ticker_mask      <- cash_flow_curr_prev$Ticker == ticker
ticker_max_year  <- max( cash_flow_curr_prev$this.year [ ticker_mask ] )
recent_year_mask <- cash_flow_curr_prev$this.year == ticker_max_year
starting_year    <- cash_flow_curr_prev[ ticker_mask & recent_year_mask , ]
}
for( future_step in 1:h ){
if( k %% h == 1 ){
new_data <- starting_year
}
new_data$prev.year      <- new_data$prev.year + 1
new_data$this.year      <- new_data$this.year + 1
new_data$prev.CF        <- new_data$this.CF
new_data$prev.CF.scaled <- new_data$this.CF.scaled
pred_i_scaled           <- predict( m1 , newdata = new_data )
pred_i_unscaled         <- pred_i_scaled * this.CF_scaled$scale[ 1 ] +
this.CF_scaled$center[ 1 ]
new_data$this.CF        <- pred_i_unscaled
new_data$this.CF.scaled <- pred_i_scaled
predictions[ k , ] <- new_data
k <- k + 1
}
predictions$Ticker[ ( k - h ):( k - 1 ) ] <- ticker
}
predictions$Ticker <- as.factor( predictions$Ticker )
results <- predictions
return( results )
}
tickers <- unique( cash_flow$Ticker )
predictions <- forecast( tickers         = tickers ,
num_years_ahead = 5 ,
history         = cash_flow_curr_prev ,
model           = m1)
history_forecast <- bind_rows( cash_flow_curr_prev , predictions )
ggplot( data =  history_forecast,
aes( x   = this.year,
y   = this.CF,
col = Ticker
)
) +
geom_line() +
xlab( "Calendar Year" ) +
ylab( "Free Cash Flow" ) +
ggtitle( "Cash Flow per Year" )
DCF <- function(
CF_t,         # array: array of precalculated CF_t
Discount_Rate # float: discount rate of each year, WACC is used here
){
DCF_partials <- cumprod( CF_t / ( 1 + Discount_Rate ) )
DCF <- sum( CF_t )
result <-  DCF
return( result )
}
tickers <- unique( cash_flow$Ticker )
wacc_list <- read.csv( paste0( data_path, "00_wacc_list.csv" ) )
dcf_list <- rep( NA , length( tickers ) )
names(dcf_list) <- tickers
k <- 1
for( ticker in tickers ){
wacc <- wacc_list$wacc[ wacc_list$Ticker == ticker ]
CF_t <- predictions$this.CF[ predictions$Ticker == ticker]
dcf_list[ k ] <- DCF(CF_t = CF_t , Discount_Rate = wacc )
k <- k + 1
}
billion <- 1000000000
# copied from yahoo finance
num_shares_B <- c( 24.6, 1.62, 5.19, 0.3932, 1.11, 0.82797, 5.62, 15.73, 2.19, 3.19, 0.77177, 0.22485, 2.36, 1.26 )
current_value_per_share <- c( 1.28, 3.73, 79, 12.76, 7.56, 9.13, 8.75, 4.38, 22.91, 8.42, 0.6, 9.88, 2.89, 10.43 )
dcf_per_share <- dcf_list / ( num_shares_B * billion )
percent_change <- ( dcf_per_share / current_value_per_share - 1 )*100
cash_per_share <- cbind( num_shares_B, current_value_per_share, dcf_per_share , percent_change)
cash_per_share
system.file(package='ggplot2')
